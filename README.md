# AdversarialAttack
programmers devcourse monthly project
![image](https://github.com/eno3940/AdversarialAttack/assets/98100556/f0d3c810-0c0c-40e4-a159-1bbad02cc8dc)
### 최종평가

**[A4팀]**

- 문제의 요구사항에 따라서 성실하게 문제를 풀어주셨습니다.
- (1) MI-FGSM, (2) Ensemble을 성실하게 적용하여 공격 성공률을 최대한 높이고자 노력하셨습니다.
- DenseNet을 사용했을 때, 단일 모델에서 좋은 공격 성공률이 보인다는 점을 보였습니다.

* (코멘트) 잘 되는 모델에 대하여 찾은 뒤에, 그것을 위주로 앙상블을 진행한 점이 인상깊습니다.

- 베스트 퍼포먼스: 6.72%가 나오셨습니다.

* 앙상블 모델의 개수가 늘어났다면, 더 성능이 잘 나올 수 있었을 것입니다.

- EfficientNet B7에 대하여 가중치를 높게 부여한 점이 인상깊고, 다른 팀에서 보지 못했던 재미있는 부분입니다.
- alpha 값이 128/255으로 더 키웠을 때, 성능이 더 올라간 것을 확인할 수 있다.

* (코멘트) 재미있는 점이고, 이것을 실험적으로 잘 보여주셔서 감사합니다.

* (코멘트) 아마 모멘텀에 영향을 미치기 때문에,

* (코멘트) 노이즈를 처음 생성할 때 alpha를 곱해서일 수도 있겠다.

- (코멘트) 다양성을 위해 batch size를 줄여서 많이 앙상블하는 게 이점이 있다고 생각합니다.

* 지금으로서는 batch size를 키우는 이유가 빠르게 결과를 내기 위해서에 가깝고, 사실상 앙상블을 위해서라면 batch size를 줄이는 게 맞습니다.

- (코멘트) EfficientNet B7처럼 큰 모델을 많이 쓰는 것보다, 사실은 조금 더 작더라도 다양한 아키텍처의 모델을 많이 쓰는 게 더 이득이지 않았을까? 라는 생각이 듭니다.
- (코멘트) 표현력이 큰 모델 => 표현력이 큰 모델이라면 perturbation과 같이 non-robust feature

* transferability가 높아질 것이라고 추측발표 점수 93 / 10 = 9.3

성능 점수 = 최종 방어 성공율: 6.72%
